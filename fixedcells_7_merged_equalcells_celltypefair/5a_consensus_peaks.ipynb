{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ab6d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:03.905207Z",
     "iopub.status.busy": "2023-02-15T14:47:03.904157Z",
     "iopub.status.idle": "2023-02-15T14:47:10.319401Z",
     "shell.execute_reply": "2023-02-15T14:47:10.317412Z",
     "shell.execute_reply.started": "2023-02-15T14:47:03.905022Z"
    },
    "papermill": {
     "duration": 11.261378,
     "end_time": "2022-09-29T13:44:58.648959",
     "exception": false,
     "start_time": "2022-09-29T13:44:47.387581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk, peak_calling\n",
    "import pyranges as pr\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5175407b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.324148Z",
     "iopub.status.busy": "2023-02-15T14:47:10.322951Z",
     "iopub.status.idle": "2023-02-15T14:47:10.595465Z",
     "shell.execute_reply": "2023-02-15T14:47:10.594185Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.324088Z"
    },
    "papermill": {
     "duration": 0.304007,
     "end_time": "2022-09-29T13:44:58.962468",
     "exception": false,
     "start_time": "2022-09-29T13:44:58.658461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffd6b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.597430Z",
     "iopub.status.busy": "2023-02-15T14:47:10.596936Z",
     "iopub.status.idle": "2023-02-15T14:47:10.657069Z",
     "shell.execute_reply": "2023-02-15T14:47:10.655760Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.597401Z"
    },
    "papermill": {
     "duration": 0.028416,
     "end_time": "2022-09-29T13:44:58.994714",
     "exception": false,
     "start_time": "2022-09-29T13:44:58.966298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get chromosome sizes (hg38)\n",
    "if not os.path.exists(\"chromsizes.txt\"):\n",
    "    target_url = (\n",
    "        \"http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\"\n",
    "    )\n",
    "    chromsizes = pd.read_csv(target_url, sep=\"\\t\", header=None)\n",
    "    chromsizes.columns = [\"Chromosome\", \"End\"]\n",
    "    chromsizes[\"Start\"] = [0] * chromsizes.shape[0]\n",
    "    chromsizes = chromsizes.loc[:, [\"Chromosome\", \"Start\", \"End\"]]\n",
    "    chromsizes = pr.PyRanges(chromsizes)\n",
    "    chromsizes.to_csv(\"chromsizes.txt\")\n",
    "    chromsizes\n",
    "else:\n",
    "    chromsizes = pd.read_csv(\"chromsizes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40497f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.660790Z",
     "iopub.status.busy": "2023-02-15T14:47:10.660201Z",
     "iopub.status.idle": "2023-02-15T14:47:10.682370Z",
     "shell.execute_reply": "2023-02-15T14:47:10.681307Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.660751Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'cistopic_objects/master_celltypefair_1.FIXEDCELLS__cto.scrublet0-4.fmx.singlets.model_28topics.pkl'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cto_consensus_paths = sorted(glob.glob(f\"cistopic_objects/*topics.pkl\"))\n",
    "cto_consensus_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x for x in cto_consensus_paths\n",
    "}\n",
    "cto_consensus_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "455d32b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.683471Z",
     "iopub.status.busy": "2023-02-15T14:47:10.683221Z",
     "iopub.status.idle": "2023-02-15T14:47:10.689814Z",
     "shell.execute_reply": "2023-02-15T14:47:10.688708Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.683448Z"
    },
    "papermill": {
     "duration": 0.013767,
     "end_time": "2022-09-29T13:44:59.037256",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.023489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragments_path_dict = {\n",
    "    \"master_celltypefair_1.FIXEDCELLS\": \"/lustre1/project/stg_00090/scatac_benchmark/fixedcells_4_merged/merged_all_1.fragments.ID.sorted.tsv.gz\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c86f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.691585Z",
     "iopub.status.busy": "2023-02-15T14:47:10.691058Z",
     "iopub.status.idle": "2023-02-15T14:47:10.774891Z",
     "shell.execute_reply": "2023-02-15T14:47:10.773694Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.691564Z"
    },
    "papermill": {
     "duration": 0.196325,
     "end_time": "2022-09-29T13:44:59.237563",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.041238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "import pyranges as pr\n",
    "import ray\n",
    "\n",
    "from pycisTopic.cistopic_class import *\n",
    "from pycisTopic.utils import *\n",
    "\n",
    "\n",
    "def export_pseudobulk(\n",
    "    input_data: Union[\"CistopicObject\", pd.DataFrame, Dict[str, pd.DataFrame]],\n",
    "    variable: str,\n",
    "    chromsizes: Union[pd.DataFrame, pr.PyRanges],\n",
    "    bed_path: str,\n",
    "    bigwig_path: str,\n",
    "    path_to_fragments: Optional[Dict[str, str]] = None,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    n_cpu: Optional[int] = 1,\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "    use_polars: Optional[bool] = True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulks as bed and bigwig from single cell fragments file given a barcode annotation.\n",
    "    Parameters\n",
    "    ---------\n",
    "    input_data: CistopicObject or pd.DataFrame\n",
    "            A :class:`CistopicObject` containing the specified `variable` as a column in :class:`CistopicObject.cell_data` or a cell metadata\n",
    "            :class:`pd.DataFrame` containing barcode as rows, containing the specified `variable` as a column (additional columns are\n",
    "            possible) and a `sample_id` column. Index names must contain the BARCODE (e.g. ATGTCGTC-1), additional tags are possible separating with -\n",
    "            (e.g. ATGCTGTGCG-1-Sample_1). The levels in the sample_id column must agree with the keys in the path_to_fragments dictionary.\n",
    "            Alternatively, if the cell metadata contains a column named barcode it will be used instead of the index names.\n",
    "    variable: str\n",
    "            A character string indicating the column that will be used to create the different group pseudobulk. It must be included in\n",
    "            the cell metadata provided as input_data.\n",
    "    chromsizes: pd.DataFrame or pr.PyRanges\n",
    "            A data frame or :class:`pr.PyRanges` containing size of each chromosome, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed files per group will be saved. If None, files will not be generated.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig files per group will be saved. If None, files will not be generated.\n",
    "    path_to_fragments: str or dict, optional\n",
    "            A dictionary of character strings, with sample name as names indicating the path to the fragments file/s from which pseudobulk profiles have to\n",
    "            be created. If a :class:`CistopicObject` is provided as input it will be ignored, but if a cell metadata :class:`pd.DataFrame` is provided it\n",
    "            is necessary to provide it. The keys of the dictionary need to match with the sample_id tag added to the index names of the input data frame.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    n_cpu: int, optional\n",
    "            Number of cores to use. Default: 1.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str, optional\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    use_polars: bool, optional\n",
    "            Whether to use polars to read fragments files. Default: True.\n",
    "    **kwargs\n",
    "            Additional parameters for ray.init()\n",
    "    Return\n",
    "    ------\n",
    "    dict\n",
    "            A dictionary containing the paths to the newly created bed fragments files per group a dictionary containing the paths to the\n",
    "            newly created bigwig files per group.\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "    # Get fragments file\n",
    "    if isinstance(input_data, CistopicObject):\n",
    "        path_to_fragments = input_data.path_to_fragments\n",
    "        if path_to_fragments is None:\n",
    "            log.error(\"No path_to_fragments in this cisTopic object.\")\n",
    "        cell_data = input_data.cell_data\n",
    "    elif isinstance(input_data, pd.DataFrame):\n",
    "        if path_to_fragments is None:\n",
    "            log.error(\"Please, provide path_to_fragments.\")\n",
    "        cell_data = input_data\n",
    "    # Check for sample_id column\n",
    "    try:\n",
    "        sample_ids = list(set(cell_data[sample_id_col]))\n",
    "    except ValueError:\n",
    "        print(\n",
    "            'Please, include a sample identification column (e.g. \"sample_id\") in your cell metadata!'\n",
    "        )\n",
    "\n",
    "    # Get fragments\n",
    "    fragments_df_dict = {}\n",
    "    for sample_id in path_to_fragments.keys():\n",
    "        if sample_id not in sample_ids:\n",
    "            log.info(\n",
    "                \"The following path_to_fragments entry is not found in the cell metadata sample_id_col: \",\n",
    "                sample_id,\n",
    "                \". It will be ignored.\",\n",
    "            )\n",
    "        else:\n",
    "            log.info(\"Reading fragments from \" + path_to_fragments[sample_id])\n",
    "            fragments_df = read_fragments_from_file(\n",
    "                path_to_fragments[sample_id], use_polars=use_polars\n",
    "            ).df\n",
    "            # Convert to int32 for memory efficiency\n",
    "            fragments_df.Start = np.int32(fragments_df.Start)\n",
    "            fragments_df.End = np.int32(fragments_df.End)\n",
    "            if \"Score\" in fragments_df:\n",
    "                fragments_df.Score = np.int32(fragments_df.Score)\n",
    "            if \"barcode\" in cell_data:\n",
    "                fragments_df = fragments_df.loc[\n",
    "                    fragments_df[\"Name\"].isin(cell_data[\"barcode\"].tolist())\n",
    "                ]\n",
    "            else:\n",
    "                fragments_df = fragments_df.loc[\n",
    "                    fragments_df[\"Name\"].isin(\n",
    "                        prepare_tag_cells(cell_data.index.tolist(), split_pattern)\n",
    "                    )\n",
    "                ]\n",
    "            fragments_df_dict[sample_id] = fragments_df\n",
    "\n",
    "    # Set groups\n",
    "    if \"barcode\" in cell_data:\n",
    "        cell_data = cell_data.loc[:, [variable, sample_id_col, \"barcode\"]]\n",
    "    else:\n",
    "        cell_data = cell_data.loc[:, [variable, sample_id_col]]\n",
    "    cell_data[variable] = cell_data[variable].replace(\" \", \"\", regex=True)\n",
    "    cell_data[variable] = cell_data[variable].replace(\"[^A-Za-z0-9]+\", \"_\", regex=True)\n",
    "    groups = sorted(list(set(cell_data[variable])))\n",
    "    # Check chromosome sizes\n",
    "    if isinstance(chromsizes, pd.DataFrame):\n",
    "        chromsizes = chromsizes.loc[:, [\"Chromosome\", \"Start\", \"End\"]]\n",
    "        chromsizes = pr.PyRanges(chromsizes)\n",
    "    # Check that output dir exist and generate output paths\n",
    "    if isinstance(bed_path, str):\n",
    "        if not os.path.exists(bed_path):\n",
    "            os.makedirs(bed_path)\n",
    "        bed_paths = {\n",
    "            group: os.path.join(bed_path, str(group) + \".bed.gz\") for group in groups\n",
    "        }\n",
    "    else:\n",
    "        bed_paths = {}\n",
    "    if isinstance(bigwig_path, str):\n",
    "        if not os.path.exists(bigwig_path):\n",
    "            os.makedirs(bigwig_path)\n",
    "        bw_paths = {\n",
    "            group: os.path.join(bigwig_path, str(group) + \".bw\") for group in groups\n",
    "        }\n",
    "    else:\n",
    "        bw_paths = {}\n",
    "    # Create pseudobulks\n",
    "    if n_cpu > 1:\n",
    "        ray.init(num_cpus=n_cpu, **kwargs)\n",
    "        ray_handle = ray.wait(\n",
    "            [\n",
    "                export_pseudobulk_ray.remote(\n",
    "                    cell_data,\n",
    "                    group,\n",
    "                    fragments_df_dict,\n",
    "                    chromsizes,\n",
    "                    bigwig_path,\n",
    "                    bed_path,\n",
    "                    sample_id_col,\n",
    "                    normalize_bigwig,\n",
    "                    remove_duplicates,\n",
    "                    split_pattern,\n",
    "                )\n",
    "                for group in groups\n",
    "            ],\n",
    "            num_returns=len(groups),\n",
    "        )\n",
    "        ray.shutdown()\n",
    "    else:\n",
    "        [\n",
    "            export_pseudobulk_one_sample(\n",
    "                cell_data,\n",
    "                group,\n",
    "                fragments_df_dict,\n",
    "                chromsizes,\n",
    "                bigwig_path,\n",
    "                bed_path,\n",
    "                sample_id_col,\n",
    "                normalize_bigwig,\n",
    "                remove_duplicates,\n",
    "                split_pattern,\n",
    "            )\n",
    "            for group in groups\n",
    "        ]\n",
    "\n",
    "    return bw_paths, bed_paths\n",
    "\n",
    "\n",
    "def export_pseudobulk_one_sample(\n",
    "    cell_data: pd.DataFrame,\n",
    "    group: str,\n",
    "    fragments_df_dict: Dict[str, pd.DataFrame],\n",
    "    chromsizes: pr.PyRanges,\n",
    "    bigwig_path: str,\n",
    "    bed_path: str,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulk as bed and bigwig from single cell fragments file given a barcode annotation and a group.\n",
    "    Parameters\n",
    "    ---------\n",
    "    cell_data: pd.DataFrame\n",
    "            A cell metadata :class:`pd.Dataframe` containing barcodes, their annotation and their sample of origin.\n",
    "    group: str\n",
    "            A character string indicating the group for which pseudobulks will be created.\n",
    "    fragments_df_dict: dict\n",
    "            A dictionary containing data frames as values with 'Chromosome', 'Start', 'End', 'Name', and 'Score' as columns; and sample label\n",
    "            as keys. 'Score' indicates the number of times that a fragments is found assigned to that barcode.\n",
    "    chromsizes: pr.PyRanges\n",
    "            A :class:`pr.PyRanges` containing size of each column, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig file will be saved.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed file will be saved.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "    log.info(\"Creating pseudobulk for \" + str(group))\n",
    "    group_fragments_list = []\n",
    "    group_fragments_dict = {}\n",
    "    for sample_id in fragments_df_dict:\n",
    "        sample_data = cell_data[cell_data.loc[:, sample_id_col].isin([sample_id])]\n",
    "        if \"barcode\" in sample_data:\n",
    "            sample_data.index = sample_data[\"barcode\"].tolist()\n",
    "        else:\n",
    "            sample_data.index = prepare_tag_cells(\n",
    "                sample_data.index.tolist(), split_pattern\n",
    "            )\n",
    "        group_var = sample_data.iloc[:, 0]\n",
    "        barcodes = group_var[group_var.isin([group])].index.tolist()\n",
    "        fragments_df = fragments_df_dict[sample_id]\n",
    "        group_fragments = fragments_df.loc[fragments_df[\"Name\"].isin(barcodes)]\n",
    "        if len(fragments_df_dict) > 1:\n",
    "            group_fragments_dict[sample_id] = group_fragments\n",
    "\n",
    "    if len(fragments_df_dict) > 1:\n",
    "        group_fragments_list = [\n",
    "            group_fragments_dict[list(group_fragments_dict.keys())[x]]\n",
    "            for x in range(len(fragments_df_dict))\n",
    "        ]\n",
    "        group_fragments = group_fragments_list[0].append(group_fragments_list[1:])\n",
    "\n",
    "    group_fragments = group_fragments[\n",
    "        group_fragments[\"Chromosome\"].isin(chromsizes.Chromosome)\n",
    "    ]\n",
    "\n",
    "    del group_fragments_dict\n",
    "    del group_fragments_list\n",
    "    del fragments_df\n",
    "    gc.collect()\n",
    "\n",
    "    group_pr = pr.PyRanges(group_fragments)\n",
    "    if isinstance(bigwig_path, str):\n",
    "        bigwig_path_group = os.path.join(bigwig_path, str(group) + \".bw\")\n",
    "        if remove_duplicates:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "            )\n",
    "        else:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "                value_col=\"Score\",\n",
    "            )\n",
    "    if isinstance(bed_path, str):\n",
    "        bed_path_group = os.path.join(bed_path, str(group) + \".bed.gz\")\n",
    "        group_pr.to_bed(\n",
    "            path=bed_path_group, keep=False, compression=\"infer\", chain=False\n",
    "        )\n",
    "\n",
    "    log.info(str(group) + \" done!\")\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def export_pseudobulk_ray(\n",
    "    cell_data: pd.DataFrame,\n",
    "    group: str,\n",
    "    fragments_df_dict: Dict[str, pd.DataFrame],\n",
    "    chromsizes: pr.PyRanges,\n",
    "    bigwig_path: str,\n",
    "    bed_path: str,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulk as bed and bigwig from single cell fragments file given a barcode annotation and a group.\n",
    "    Parameters\n",
    "    ---------\n",
    "    cell_data: pd.DataFrame\n",
    "            A cell metadata :class:`pd.Dataframe` containing barcodes, their annotation and their sample of origin.\n",
    "    group: str\n",
    "            A character string indicating the group for which pseudobulks will be created.\n",
    "    fragments_df_dict: dict\n",
    "            A dictionary containing data frames as values with 'Chromosome', 'Start', 'End', 'Name', and 'Score' as columns; and sample label\n",
    "            as keys. 'Score' indicates the number of times that a fragments is found assigned to that barcode.\n",
    "    chromsizes: pr.PyRanges\n",
    "            A :class:`pr.PyRanges` containing size of each column, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed file will be saved.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig file will be saved.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    \"\"\"\n",
    "    export_pseudobulk_one_sample(\n",
    "        cell_data,\n",
    "        group,\n",
    "        fragments_df_dict,\n",
    "        chromsizes,\n",
    "        bigwig_path,\n",
    "        bed_path,\n",
    "        sample_id_col,\n",
    "        normalize_bigwig,\n",
    "        remove_duplicates,\n",
    "        split_pattern,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b06107",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.776004Z",
     "iopub.status.busy": "2023-02-15T14:47:10.775791Z",
     "iopub.status.idle": "2023-02-15T14:47:10.796367Z",
     "shell.execute_reply": "2023-02-15T14:47:10.795370Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.775984Z"
    },
    "papermill": {
     "duration": 0.022853,
     "end_time": "2022-09-29T13:44:59.264456",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.241603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_pseudobulk_bed_files exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "# for sample in [\"BRO_mtscatac_1.LIBDS\"]:\n",
    "bw_paths_dict = {}\n",
    "bed_paths_dict = {}\n",
    "\n",
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    print(\"Shutting down Ray\")\n",
    "    ray.shutdown()\n",
    "\n",
    "for sample in cto_consensus_path_dict.keys():\n",
    "    supersample = \".\".join(sample.split(\".\")[:2])\n",
    "\n",
    "    bed_path = os.path.join(\n",
    "        \"final_consensus_peaks\", f\"{sample}__SCREEN_pseudobulk_bed_files\"\n",
    "    )\n",
    "    bw_path = os.path.join(\n",
    "        \"final_consensus_peaks\", f\"{sample}__SCREEN_pseudobulk_bw_files\"\n",
    "    )\n",
    "    if not os.path.exists(bed_path):\n",
    "        cto_path = cto_consensus_path_dict[sample]\n",
    "        with open(cto_path, \"rb\") as f:\n",
    "            cto = pickle.load(f)\n",
    "\n",
    "            bw_paths, bed_paths = export_pseudobulk(\n",
    "                input_data=cto,\n",
    "                variable=\"harmony_consensus_cell_type__mega\",\n",
    "                sample_id_col=\"sample_id\",\n",
    "                chromsizes=chromsizes,\n",
    "                bed_path=bed_path,\n",
    "                bigwig_path=bw_path,\n",
    "                path_to_fragments=fragments_path_dict[supersample],\n",
    "                n_cpu=16,\n",
    "                normalize_bigwig=True,\n",
    "                remove_duplicates=True,\n",
    "            )\n",
    "\n",
    "            if ray.is_initialized():\n",
    "                print(\"Shutting down Ray\")\n",
    "                ray.shutdown()\n",
    "    else:\n",
    "        print(f\"{bed_path} exists, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388673e2-b19f-499a-ae2b-4e49b039c2b4",
   "metadata": {},
   "source": [
    "# write per tech-cell type pseudobulk, nonnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f302f4d-5228-42c9-92b4-8d4feece4468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.797386Z",
     "iopub.status.busy": "2023-02-15T14:47:10.797184Z",
     "iopub.status.idle": "2023-02-15T14:47:10.815921Z",
     "shell.execute_reply": "2023-02-15T14:47:10.814904Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.797366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per_tech_cell_type_bigwigs_nonnorm/master_celltypefair_1.FIXEDCELLS__CONSENSUS_pseudobulk_bed_files_nonnorm exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "# for sample in [\"BRO_mtscatac_1.LIBDS\"]:\n",
    "bw_paths_dict = {}\n",
    "bed_paths_dict = {}\n",
    "\n",
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    print(\"Shutting down Ray\")\n",
    "    ray.shutdown()\n",
    "\n",
    "for sample in cto_consensus_path_dict.keys():\n",
    "    supersample = \".\".join(sample.split(\".\")[:2])\n",
    "\n",
    "    bed_path = os.path.join(\n",
    "        \"per_tech_harmony_cell_type_bigwigs_nonnorm\",\n",
    "        f\"{sample}__CONSENSUS_pseudobulk_bed_files_nonnorm\",\n",
    "    )\n",
    "    bw_path = os.path.join(\n",
    "        \"per_tech_harmony_cell_type_bigwigs_nonnorm\",\n",
    "        f\"{sample}__CONSENSUS_pseudobulk_bw_files_nonnorm\",\n",
    "    )\n",
    "    if not os.path.exists(bed_path):\n",
    "        cto_path = cto_consensus_path_dict[sample]\n",
    "        with open(cto_path, \"rb\") as f:\n",
    "            cto = pickle.load(f)\n",
    "\n",
    "            cto.cell_data[\"tech_consensus_cell_type\"] = (\n",
    "                cto.cell_data[\"tech\"]\n",
    "                + \"__\"\n",
    "                + [\n",
    "                    x.replace(\" \", \"_\")\n",
    "                    for x in cto.cell_data[\"harmony_consensus_cell_type__mega\"]\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            bw_paths, bed_paths = export_pseudobulk(\n",
    "                input_data=cto,\n",
    "                variable=\"tech_consensus_cell_type\",\n",
    "                sample_id_col=\"sample_id\",\n",
    "                chromsizes=chromsizes,\n",
    "                bed_path=bed_path,\n",
    "                bigwig_path=bw_path,\n",
    "                path_to_fragments=fragments_path_dict[supersample],\n",
    "                n_cpu=8,\n",
    "                normalize_bigwig=False,\n",
    "                remove_duplicates=True,\n",
    "            )\n",
    "\n",
    "            if ray.is_initialized():\n",
    "                print(\"Shutting down Ray\")\n",
    "                ray.shutdown()\n",
    "    else:\n",
    "        print(f\"{bed_path} exists, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6efe9d",
   "metadata": {
    "papermill": {
     "duration": 0.003844,
     "end_time": "2022-09-29T13:44:59.272330",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.268486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a822fdf1-bc5e-4f87-8e5a-09411928b6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.816983Z",
     "iopub.status.busy": "2023-02-15T14:47:10.816783Z",
     "iopub.status.idle": "2023-02-15T14:47:10.826895Z",
     "shell.execute_reply": "2023-02-15T14:47:10.825936Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.816965Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS.FIXEDCELLS__cto': 'cistopic_objects/master_celltypefair_1.FIXEDCELLS__cto.scrublet0-4.fmx.singlets.model_28topics.pkl'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cto_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0] + \".\" + x.split(\"/\")[-1].split(f\".\")[-6]: x\n",
    "    for x in sorted(glob.glob(\"cistopic_objects/*topics.pkl\"))\n",
    "}\n",
    "cto_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "967b65dd-c1f5-4399-abdc-2ce2a04e3990",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:10.830076Z",
     "iopub.status.busy": "2023-02-15T14:47:10.829849Z",
     "iopub.status.idle": "2023-02-15T14:47:15.903557Z",
     "shell.execute_reply": "2023-02-15T14:47:15.902345Z",
     "shell.execute_reply.started": "2023-02-15T14:47:10.830057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample, cto_path in cto_path_dict.items():\n",
    "    with open(cto_path, \"rb\") as f:\n",
    "        cto = pickle.load(f)\n",
    "\n",
    "    cto.cell_data.to_csv(cto_path.replace(\".pkl\", \".cell_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4973647b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.904991Z",
     "iopub.status.busy": "2023-02-15T14:47:15.904766Z",
     "iopub.status.idle": "2023-02-15T14:47:15.914514Z",
     "shell.execute_reply": "2023-02-15T14:47:15.913570Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.904970Z"
    },
    "papermill": {
     "duration": 0.014072,
     "end_time": "2022-09-29T13:44:59.290366",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.276294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'cistopic_objects/master_celltypefair_1.FIXEDCELLS__cto.scrublet0-4.fmx.singlets.model_28topics.cell_data.csv'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_data_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"cistopic_objects/*topics.cell_data.csv\"))\n",
    "}\n",
    "cell_data_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae58dd8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.915631Z",
     "iopub.status.busy": "2023-02-15T14:47:15.915425Z",
     "iopub.status.idle": "2023-02-15T14:47:15.924599Z",
     "shell.execute_reply": "2023-02-15T14:47:15.923671Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.915613Z"
    },
    "papermill": {
     "duration": 0.013606,
     "end_time": "2022-09-29T13:44:59.308231",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.294625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_pseudobulk_bw_files'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"final_consensus_peaks/*_pseudobulk_bw_files\"))\n",
    "}\n",
    "bw_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e57cc13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.925549Z",
     "iopub.status.busy": "2023-02-15T14:47:15.925347Z",
     "iopub.status.idle": "2023-02-15T14:47:15.934593Z",
     "shell.execute_reply": "2023-02-15T14:47:15.933637Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.925531Z"
    },
    "papermill": {
     "duration": 0.013527,
     "end_time": "2022-09-29T13:44:59.326142",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.312615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_pseudobulk_bed_files'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bed_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"final_consensus_peaks/*_pseudobulk_bed_files\"))\n",
    "}\n",
    "bed_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24cad54b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.936183Z",
     "iopub.status.busy": "2023-02-15T14:47:15.935580Z",
     "iopub.status.idle": "2023-02-15T14:47:15.943872Z",
     "shell.execute_reply": "2023-02-15T14:47:15.942926Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.936155Z"
    },
    "papermill": {
     "duration": 0.03679,
     "end_time": "2022-09-29T13:44:59.367367",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.330577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in bed_path_dict.keys():\n",
    "    bed_paths = {\n",
    "        x.split(\"/\")[-1].split(\"__\")[0].split(\".bed.gz\")[0]: x\n",
    "        for x in glob.glob(bed_path_dict[sample] + \"/*\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe713275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.945361Z",
     "iopub.status.busy": "2023-02-15T14:47:15.944862Z",
     "iopub.status.idle": "2023-02-15T14:47:15.950266Z",
     "shell.execute_reply": "2023-02-15T14:47:15.949299Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.945340Z"
    },
    "papermill": {
     "duration": 0.009409,
     "end_time": "2022-09-29T13:44:59.381354",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.371945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99ef9f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.951393Z",
     "iopub.status.busy": "2023-02-15T14:47:15.951184Z",
     "iopub.status.idle": "2023-02-15T14:47:15.957085Z",
     "shell.execute_reply": "2023-02-15T14:47:15.956124Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.951374Z"
    },
    "papermill": {
     "duration": 0.009207,
     "end_time": "2022-09-29T13:44:59.394975",
     "exception": false,
     "start_time": "2022-09-29T13:44:59.385768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968dd901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226e07e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.958646Z",
     "iopub.status.busy": "2023-02-15T14:47:15.958398Z",
     "iopub.status.idle": "2023-02-15T14:47:15.984974Z",
     "shell.execute_reply": "2023-02-15T14:47:15.983978Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.958624Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2022-09-29T13:44:59.399469",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_narrow_peaks_dict.pkl already exists\n"
     ]
    }
   ],
   "source": [
    "narrow_peaks_dict = {}\n",
    "ray.shutdown()\n",
    "for sample in bed_path_dict.keys():\n",
    "    narrow_peaks_dict_path = bed_path_dict[sample].replace(\n",
    "        \"_pseudobulk_bed_files\", \"_narrow_peaks_dict.pkl\"\n",
    "    )\n",
    "    peak_path = os.path.join(\n",
    "        \"final_consensus_peaks\", f\"{sample}__SCREEN_consensus_peaks\"\n",
    "    )\n",
    "    if not os.path.exists(peak_path):\n",
    "        os.mkdir(peak_path)\n",
    "\n",
    "    if not os.path.exists(narrow_peaks_dict_path):\n",
    "        cell_data = pd.read_csv(cell_data_path_dict[sample])\n",
    "        cto_celltypes = set(\n",
    "            [\n",
    "                x.replace(\" \", \"\").replace(\"+\", \"\").replace(\"_\", \"\")\n",
    "                for x in set(cell_data[\"harmony_consensus_cell_type__mega\"].unique())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        bed_celltypes = set(\n",
    "            [\n",
    "                x.split(\".\")[0].replace(\"+\", \"\").replace(\"_\", \"\")\n",
    "                for x in os.listdir(bed_path_dict[sample])\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if cto_celltypes == bed_celltypes:\n",
    "            print(f\"Starting {narrow_peaks_dict_path}\")\n",
    "            bed_paths = {\n",
    "                x.split(\"/\")[-1].split(\"__\")[0].split(\".bed.gz\")[0]: x\n",
    "                for x in glob.glob(bed_path_dict[sample] + \"/*\")\n",
    "            }\n",
    "            narrow_peaks_dict = peak_calling(\n",
    "                macs_path=\"macs2\",\n",
    "                bed_paths=bed_paths,\n",
    "                outdir=peak_path,\n",
    "                genome_size=\"hs\",\n",
    "                n_cpu=16,\n",
    "                input_format=\"BEDPE\",\n",
    "                shift=73,\n",
    "                ext_size=146,\n",
    "                keep_dup=\"all\",\n",
    "                q_value=0.05,\n",
    "            )\n",
    "            with open(narrow_peaks_dict_path, \"wb\") as f:\n",
    "                pickle.dump(narrow_peaks_dict, f)\n",
    "        else:\n",
    "            print(f\"{sample} cell types not matching!! Rerun bed file writing.\")\n",
    "            print(f\"\\t{bed_celltypes}\")\n",
    "            print(f\"\\t{cto_celltypes}\")\n",
    "    else:\n",
    "        print(f\"{narrow_peaks_dict_path} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c78082",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# call consensus peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05250c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.986816Z",
     "iopub.status.busy": "2023-02-15T14:47:15.985901Z",
     "iopub.status.idle": "2023-02-15T14:47:15.994340Z",
     "shell.execute_reply": "2023-02-15T14:47:15.993185Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.986795Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.iterative_peak_calling import get_consensus_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d953251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:15.995771Z",
     "iopub.status.busy": "2023-02-15T14:47:15.995422Z",
     "iopub.status.idle": "2023-02-15T14:47:16.005636Z",
     "shell.execute_reply": "2023-02-15T14:47:16.004627Z",
     "shell.execute_reply.started": "2023-02-15T14:47:15.995748Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_narrow_peaks_dict.pkl'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrow_peaks_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"final_consensus_peaks/*_narrow_peaks_dict.pkl\"))\n",
    "}\n",
    "narrow_peaks_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdf86ecd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:16.007414Z",
     "iopub.status.busy": "2023-02-15T14:47:16.006698Z",
     "iopub.status.idle": "2023-02-15T14:47:16.012072Z",
     "shell.execute_reply": "2023-02-15T14:47:16.011074Z",
     "shell.execute_reply.started": "2023-02-15T14:47:16.007390Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_blacklist = \"../0_resources/regions/hg38-blacklist.v2.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff977fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:16.013541Z",
     "iopub.status.busy": "2023-02-15T14:47:16.013218Z",
     "iopub.status.idle": "2023-02-15T14:47:16.097998Z",
     "shell.execute_reply": "2023-02-15T14:47:16.096641Z",
     "shell.execute_reply.started": "2023-02-15T14:47:16.013519Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_celltypefair_1.FIXEDCELLS\n",
      "final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_consensus_peaks.bed already exists, skipping...\n"
     ]
    }
   ],
   "source": [
    "peak_half_width = 250\n",
    "\n",
    "# Get consensus peaks\n",
    "consensus_peaks_dict = {}\n",
    "for sample in narrow_peaks_path_dict.keys():\n",
    "    print(sample)\n",
    "    consensus_out_path = narrow_peaks_path_dict[sample].replace(\n",
    "        \"_narrow_peaks_dict.pkl\", \"_consensus_peaks.bed\"\n",
    "    )\n",
    "    if not os.path.exists(consensus_out_path):\n",
    "        cell_data = pd.read_csv(cell_data_path_dict[sample])\n",
    "        cto_celltypes = set(\n",
    "            [\n",
    "                x.replace(\" \", \"\").replace(\"+\", \"\").replace(\"_\", \"\")\n",
    "                for x in set(cell_data[\"harmony_consensus_cell_type__mega\"].unique())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with open(narrow_peaks_path_dict[sample], \"rb\") as f:\n",
    "            narrow_peaks_dict = pickle.load(f)\n",
    "        peaks_celltypes = set(\n",
    "            [\n",
    "                x.replace(\" \", \"\").replace(\"+\", \"\").replace(\"_\", \"\")\n",
    "                for x in set(narrow_peaks_dict.keys())\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if cto_celltypes == peaks_celltypes:\n",
    "            consensus_peaks = get_consensus_peaks(\n",
    "                narrow_peaks_dict,\n",
    "                peak_half_width,\n",
    "                chromsizes=chromsizes,\n",
    "                path_to_blacklist=path_to_blacklist,\n",
    "            )\n",
    "\n",
    "            consensus_peaks.to_bed(\n",
    "                path=consensus_out_path, keep=True, compression=\"infer\", chain=False\n",
    "            )\n",
    "        else:\n",
    "            print(\"CELL TYPE SETS NOT MATCHING! Rerun peak calling.\")\n",
    "            print(peaks_celltypes - cto_celltypes)\n",
    "            print(cto_celltypes - peaks_celltypes)\n",
    "    else:\n",
    "        print(f\"{consensus_out_path} already exists, skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b93db-4d5b-44a7-9754-6ff60f4cb730",
   "metadata": {},
   "source": [
    "# write top 20 and bot 20 pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15e03171-b47c-4625-80c7-043d68d2dff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:16.099922Z",
     "iopub.status.busy": "2023-02-15T14:47:16.099414Z",
     "iopub.status.idle": "2023-02-15T14:47:16.109139Z",
     "shell.execute_reply": "2023-02-15T14:47:16.108070Z",
     "shell.execute_reply.started": "2023-02-15T14:47:16.099890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "peak_path_dict = {\n",
    "    x.split(\"/\")[-1].split(\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"final_consensus_peaks/*peaks.bed\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4f2709-0caf-4dd0-a993-29765db99253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:16.110552Z",
     "iopub.status.busy": "2023-02-15T14:47:16.110278Z",
     "iopub.status.idle": "2023-02-15T14:47:17.697155Z",
     "shell.execute_reply": "2023-02-15T14:47:17.696087Z",
     "shell.execute_reply.started": "2023-02-15T14:47:16.110527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_celltypefair_1.FIXEDCELLS\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.DataFrame()\n",
    "for sample, peak_path in peak_path_dict.items():\n",
    "    print(sample)\n",
    "    df = pd.read_csv(peak_path, sep=\"\\t\", header=None)\n",
    "    df[\"sample\"] = sample\n",
    "    df.columns = [\n",
    "        \"chrom\",\n",
    "        \"start\",\n",
    "        \"end\",\n",
    "        \"cell_type\",\n",
    "        \"score\",\n",
    "        \"strand\",\n",
    "        \"sample\",\n",
    "    ]\n",
    "    percentile_val = np.percentile(df[\"score\"], 80)\n",
    "    df_sub = df[df[\"score\"] > percentile_val]\n",
    "    peak_path_new = peak_path.replace(\".bed\", \"__top20pct.bed\")\n",
    "\n",
    "    df_sub.drop(\"sample\", axis=1).to_csv(\n",
    "        peak_path_new, sep=\"\\t\", header=False, index=False\n",
    "    )\n",
    "\n",
    "    percentile_val = np.percentile(df[\"score\"], 20)\n",
    "    df_sub = df[df[\"score\"] < percentile_val]\n",
    "    peak_path_new = peak_path.replace(\".bed\", \"__bot20pct.bed\")\n",
    "\n",
    "    df_sub.drop(\"sample\", axis=1).to_csv(\n",
    "        peak_path_new, sep=\"\\t\", header=False, index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28256990",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Check % chrM in consensus peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d338fe42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:17.698556Z",
     "iopub.status.busy": "2023-02-15T14:47:17.698325Z",
     "iopub.status.idle": "2023-02-15T14:47:17.708091Z",
     "shell.execute_reply": "2023-02-15T14:47:17.707149Z",
     "shell.execute_reply.started": "2023-02-15T14:47:17.698534Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'master_celltypefair_1.FIXEDCELLS': 'final_consensus_peaks/master_celltypefair_1.FIXEDCELLS__SCREEN_consensus_peaks.bed'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consensus_peaks_path_dict = {\n",
    "    x.split(\"/\")[-1].split(f\"__\")[0]: x\n",
    "    for x in sorted(glob.glob(\"final_consensus_peaks/*consensus_peaks.bed\"))\n",
    "}\n",
    "consensus_peaks_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58c7f4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T14:47:17.709394Z",
     "iopub.status.busy": "2023-02-15T14:47:17.709055Z",
     "iopub.status.idle": "2023-02-15T14:47:18.316295Z",
     "shell.execute_reply": "2023-02-15T14:47:18.315200Z",
     "shell.execute_reply.started": "2023-02-15T14:47:17.709376Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master_celltypefair_1.FIXEDCELLS\n",
      "\tpeaks on standard chromosomes: 326256\n",
      "\tpeaks on contigs: 542\n",
      "\tpeaks on chrM: 21\n",
      "\t% peaks non standard chromosomes: 0.17226660628666018%\n",
      "\tpeaks on chrY: 185\n"
     ]
    }
   ],
   "source": [
    "for sample, path in consensus_peaks_path_dict.items():\n",
    "    print(sample)\n",
    "    peaks_df = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "\n",
    "    chroms_in_df = list(sorted(peaks_df[0].unique()))\n",
    "    chroms_standard = [\"chr\" + str(x + 1) for x in range(22)] + [\"chrX\"]\n",
    "    chroms_nonstandard = list(set(chroms_in_df) - set(chroms_standard) - set([\"chrM\"]))\n",
    "\n",
    "    n_standard = peaks_df[0].value_counts()[chroms_standard].sum()\n",
    "    n_contigs = peaks_df[0].value_counts()[chroms_nonstandard].sum()\n",
    "    n_chrm = peaks_df[0].value_counts()[\"chrM\"].sum()\n",
    "    pct_nonstandard = (n_contigs + n_chrm) / len(peaks_df) * 100\n",
    "\n",
    "    print(f\"\\tpeaks on standard chromosomes: {n_standard}\")\n",
    "    print(f\"\\tpeaks on contigs: {n_contigs}\")\n",
    "    print(f\"\\tpeaks on chrM: {n_chrm}\")\n",
    "    print(f\"\\t% peaks non standard chromosomes: {pct_nonstandard}%\")\n",
    "    if \"chrY\" in chroms_in_df:\n",
    "        n_chrY = peaks_df[0].value_counts()[\"chrY\"].sum()\n",
    "        print(f\"\\tpeaks on chrY: {n_chrY}\")\n",
    "    else:\n",
    "        print(f\"\\tpeaks on chrY: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c3cb2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74249f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ea69c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20221014_pycistopic.sif",
   "language": "python",
   "name": "cistopic_20221014"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "8_consensus_peaks.ipynb",
   "output_path": "8_consensus_peaks.OUT.ipynb",
   "parameters": {},
   "start_time": "2022-09-29T13:44:40.536795",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
